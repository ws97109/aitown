"""
AIå±…æ°‘å•å·å¡«å¯«å™¨ - ç´” Ollama LLM ç‰ˆæœ¬
æ‰€æœ‰å›ç­”å‡ç”± Ollama LLM æ ¹æ“š agent.json å’Œ simulation.md ç”Ÿæˆ
ä¸ä½¿ç”¨ä»»ä½•ç¡¬ç·¨ç¢¼æˆ–è¦å‰‡å¼•æ“
"""

import sys
import os
import json
from typing import Dict, List, Any, Optional

# æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘ï¼Œä»¥ä¾¿å°å…¥éŠæˆ²æ¨¡çµ„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from .models import Survey, SurveyResponse, SurveyManager
from .ollama_generator import OllamaSurveyGenerator


class AIResidentSurveyFiller:
    """AIå±…æ°‘å•å·å¡«å¯«å™¨ - ç´” LLM é©…å‹•ï¼Œç„¡ç¡¬ç·¨ç¢¼è¦å‰‡"""

    def __init__(self, survey_manager: SurveyManager, simulation_md_path: Optional[str] = None):
        """
        åˆå§‹åŒ–AIå±…æ°‘å•å·å¡«å¯«å™¨

        Args:
            survey_manager: å•å·ç®¡ç†å™¨
            simulation_md_path: simulation.mdæ–‡ä»¶è·¯å¾‘ï¼ˆåŒ…å«æ´»å‹•æ­·å²ï¼‰
        """
        self.survey_manager = survey_manager
        self.game = None

        # å‹•æ…‹è¼‰å…¥AIå±…æ°‘åŸºæœ¬ä¿¡æ¯ï¼ˆç”¨æ–¼åˆ—è¡¨å’Œé©—è­‰ï¼‰
        self.residents_info = self._load_residents_info()

        # åˆå§‹åŒ–Ollamaç”Ÿæˆå™¨ï¼ˆå¿…éœ€ï¼‰
        if not simulation_md_path:
            print("âš ï¸  è­¦å‘Šï¼šæœªæä¾› simulation_md_pathï¼Œå°‡ç„¡æ³•ä½¿ç”¨æ´»å‹•æ­·å²")

        self.ollama_generator = OllamaSurveyGenerator(simulation_md_path)
        print(f"âœ“ Ollama ç”Ÿæˆå™¨å·²åˆå§‹åŒ–ï¼ˆç´” LLM æ¨¡å¼ï¼Œç„¡ç¡¬ç·¨ç¢¼è¦å‰‡ï¼‰")

    def _load_residents_info(self) -> Dict[str, Dict]:
        """
        å‹•æ…‹è¼‰å…¥AIå±…æ°‘åŸºæœ¬ä¿¡æ¯
        åƒ…ç”¨æ–¼ç²å–å±…æ°‘åˆ—è¡¨ï¼Œä¸ç”¨æ–¼ç”Ÿæˆå›ç­”
        """
        try:
            # å˜—è©¦å¾agenté…ç½®æ–‡ä»¶è¼‰å…¥
            agents_path = "../frontend/static/assets/village/agents"
            if not os.path.exists(agents_path):
                agents_path = "frontend/static/assets/village/agents"

            residents_info = {}

            if os.path.exists(agents_path):
                for agent_dir in os.listdir(agents_path):
                    agent_config_path = os.path.join(agents_path, agent_dir, "agent.json")
                    if os.path.exists(agent_config_path):
                        try:
                            with open(agent_config_path, "r", encoding="utf-8") as f:
                                agent_config = json.load(f)

                            agent_name = agent_config.get("name", agent_dir)
                            scratch = agent_config.get("scratch", {})

                            # åƒ…ä¿å­˜åŸºæœ¬ä¿¡æ¯ç”¨æ–¼åˆ—è¡¨é¡¯ç¤º
                            residents_info[agent_name] = {
                                "age": scratch.get("age", 25),
                                "personality": scratch.get("innate", "").split("ã€") if scratch.get("innate") else [],
                                "current_activity": agent_config.get("currently", "")
                            }
                        except json.JSONDecodeError:
                            print(f"âš ï¸  ç„¡æ³•è§£æ {agent_config_path}")
                            continue

            if not residents_info:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½• AI å±…æ°‘é…ç½®æ–‡ä»¶")
                print(f"   è«‹ç¢ºèªè·¯å¾‘: {agents_path}")

            return residents_info

        except Exception as e:
            print(f"âŒ è¼‰å…¥AIå±…æ°‘ä¿¡æ¯å¤±æ•—: {e}")
            return {}

    def set_game_context(self):
        """è¨­ç½®éŠæˆ²ä¸Šä¸‹æ–‡ï¼ˆä¿ç•™æ¥å£å…¼å®¹æ€§ï¼‰"""
        pass

    def fill_survey_for_all_residents(self, survey_id: str) -> List[SurveyResponse]:
        """
        è®“æ‰€æœ‰AIå±…æ°‘å¡«å¯«å•å·
        ä½¿ç”¨ç´” Ollama LLM ç”Ÿæˆæ‰€æœ‰å›ç­”

        Args:
            survey_id: å•å·ID

        Returns:
            æ‰€æœ‰å±…æ°‘çš„å›æ‡‰åˆ—è¡¨
        """
        survey = self.survey_manager.load_survey(survey_id)
        if not survey:
            raise ValueError(f"å•å· {survey_id} ä¸å­˜åœ¨")

        print(f"\nğŸ“‹ é–‹å§‹ç‚ºæ‰€æœ‰å±…æ°‘å¡«å¯«å•å·: {survey.title}")
        print(f"   å…± {len(self.residents_info)} ä½å±…æ°‘")
        print(f"   å•å·åŒ…å« {len(survey.questions)} å€‹å•é¡Œ")
        print(f"   ä½¿ç”¨ Ollama LLM ç”Ÿæˆæ‰€æœ‰å›ç­”\n")

        responses = []
        for i, resident_name in enumerate(self.residents_info.keys(), 1):
            print(f"[{i}/{len(self.residents_info)}] æ­£åœ¨ç‚º {resident_name} ç”Ÿæˆå›ç­”...")

            try:
                response = self.fill_survey_for_resident(survey_id, resident_name)
                if response:
                    responses.append(response)
                    print(f"   âœ“ {resident_name} å®Œæˆ")
            except Exception as e:
                print(f"   âŒ {resident_name} å¤±æ•—: {e}")
                continue

        print(f"\nâœ… å®Œæˆï¼æˆåŠŸç”Ÿæˆ {len(responses)}/{len(self.residents_info)} ä»½å•å·å›æ‡‰")
        return responses

    def fill_survey_for_resident(self, survey_id: str, resident_name: str) -> Optional[SurveyResponse]:
        """
        è®“ç‰¹å®šAIå±…æ°‘å¡«å¯«å•å·
        ä½¿ç”¨ç´” Ollama LLM ç”Ÿæˆæ‰€æœ‰å›ç­”

        Args:
            survey_id: å•å·ID
            resident_name: å±…æ°‘å§“å

        Returns:
            å•å·å›æ‡‰å°è±¡
        """
        survey = self.survey_manager.load_survey(survey_id)
        if not survey:
            raise ValueError(f"å•å· {survey_id} ä¸å­˜åœ¨")

        if resident_name not in self.residents_info:
            raise ValueError(f"AIå±…æ°‘ {resident_name} ä¸å­˜åœ¨")

        # ä½¿ç”¨ç´” LLM ç”Ÿæˆå›æ‡‰
        response = self._generate_resident_response_via_llm(survey, resident_name)

        if response:
            self.survey_manager.save_response(response)

        return response

    def _generate_resident_response_via_llm(self, survey: Survey, resident_name: str) -> SurveyResponse:
        """
        ç‚ºç‰¹å®šå±…æ°‘ç”Ÿæˆå•å·å›æ‡‰ - ç´” LLM é©…å‹•

        Args:
            survey: å•å·å°è±¡
            resident_name: å±…æ°‘å§“å

        Returns:
            å•å·å›æ‡‰å°è±¡
        """
        response = SurveyResponse(survey.survey_id, resident_name)

        print(f"   ğŸ“ å•å·: {survey.title}")
        print(f"   ğŸ¤– ä½¿ç”¨ Ollama LLM ç”Ÿæˆ {len(survey.questions)} å€‹å›ç­”...")

        for i, question in enumerate(survey.questions, 1):
            try:
                # ä½¿ç”¨ Ollama ç”Ÿæˆå›ç­”ï¼ˆç„¡ fallback åˆ°è¦å‰‡å¼•æ“ï¼‰
                answer = self._generate_answer_via_ollama(
                    question=question,
                    resident_name=resident_name
                )

                response.add_response(question["id"], answer)
                print(f"      [{i}/{len(survey.questions)}] {question['text'][:30]}... âœ“")

            except Exception as e:
                print(f"      [{i}/{len(survey.questions)}] {question['text'][:30]}... âŒ éŒ¯èª¤: {e}")
                # ç™¼ç”ŸéŒ¯èª¤æ™‚ä½¿ç”¨é€šç”¨å›ç­”ï¼Œè€Œéç¡¬ç·¨ç¢¼è¦å‰‡
                answer = self._get_error_fallback_answer(question["type"])
                response.add_response(question["id"], answer)

        response.complete()
        return response

    def _generate_answer_via_ollama(self, question: Dict, resident_name: str) -> Any:
        """
        ä½¿ç”¨ Ollama LLM ç”Ÿæˆå•å·å›ç­”

        Args:
            question: å•é¡Œå­—å…¸
            resident_name: å±…æ°‘å§“å

        Returns:
            ç”Ÿæˆçš„å›ç­”
        """
        question_type = question["type"]
        question_text = question["text"]
        options = question.get("options", [])

        # èª¿ç”¨ Ollama ç”Ÿæˆå™¨ï¼ˆä¸ä½¿ç”¨ resident_infoï¼Œå› ç‚º generator æœƒç›´æ¥è®€å– agent.jsonï¼‰
        llm_response = self.ollama_generator.generate_response(
            resident_name=resident_name,
            resident_info={},  # ç©ºå­—å…¸ï¼Œgenerator æœƒè‡ªå·±è¼‰å…¥ agent.json
            question_text=question_text,
            question_type=question_type,
            options=options
        )

        # è™•ç† LLM å›æ‡‰æ ¼å¼
        return self._process_llm_response(llm_response, question_type, options)

    def _process_llm_response(self, llm_response: str, question_type: str, options: List[str]) -> Any:
        """
        è™•ç† LLM ç”Ÿæˆçš„å›æ‡‰ï¼Œç¢ºä¿æ ¼å¼æ­£ç¢º

        Args:
            llm_response: LLM åŸå§‹å›æ‡‰
            question_type: å•é¡Œé¡å‹
            options: é¸é …åˆ—è¡¨

        Returns:
            æ ¼å¼åŒ–å¾Œçš„å›ç­”
        """
        if not llm_response:
            return self._get_error_fallback_answer(question_type)

        llm_response = llm_response.strip()

        if question_type == "single_choice":
            # å–®é¸é¡Œï¼šåŒ¹é…é¸é …
            for option in options:
                # ç²¾ç¢ºåŒ¹é…æˆ–åŒ…å«åŒ¹é…
                if option == llm_response or option in llm_response or llm_response in option:
                    return option

            # å¦‚æœç„¡æ³•åŒ¹é…ï¼Œå˜—è©¦æ¨¡ç³ŠåŒ¹é…
            for option in options:
                option_words = set(option.replace("ã€", " ").replace("ï¼Œ", " ").split())
                response_words = set(llm_response.replace("ã€", " ").replace("ï¼Œ", " ").split())
                if option_words & response_words:  # æœ‰äº¤é›†
                    return option

            # ä»ç„¡æ³•åŒ¹é…ï¼Œè¿”å› LLM åŸå§‹å›æ‡‰
            print(f"         âš ï¸  ç„¡æ³•åŒ¹é…é¸é …ï¼Œä½¿ç”¨ LLM åŸå§‹å›æ‡‰: {llm_response}")
            return llm_response

        elif question_type == "multiple_choice":
            # å¤šé¸é¡Œï¼šæå–æ‰€æœ‰åŒ¹é…çš„é¸é …
            selected = []
            for option in options:
                if option in llm_response:
                    selected.append(option)

            if selected:
                return selected

            # å˜—è©¦ç”¨é “è™Ÿæˆ–é€—è™Ÿåˆ†å‰²
            parts = llm_response.replace("ã€", ",").replace("ï¼Œ", ",").split(",")
            for part in parts:
                part = part.strip()
                for option in options:
                    if part in option or option in part:
                        if option not in selected:
                            selected.append(option)

            if selected:
                return selected

            # ç„¡æ³•åŒ¹é…ï¼Œè¿”å›åŸå§‹å›æ‡‰ä½œç‚ºåˆ—è¡¨
            print(f"         âš ï¸  ç„¡æ³•åŒ¹é…é¸é …ï¼Œä½¿ç”¨ LLM åŸå§‹å›æ‡‰")
            return [llm_response]

        elif question_type == "rating":
            # è©•åˆ†é¡Œï¼šæå–æ•¸å­—
            import re
            match = re.search(r'(\d+)', llm_response)
            if match:
                rating = int(match.group(1))
                # ç¢ºä¿åœ¨ç¯„åœå…§
                if 1 <= rating <= 10:
                    return rating
                else:
                    return max(1, min(10, rating))  # é™åˆ¶ç¯„åœ

            # ç„¡æ³•æå–æ•¸å­—ï¼Œè¿”å› 5
            print(f"         âš ï¸  ç„¡æ³•æå–è©•åˆ†ï¼Œä½¿ç”¨é è¨­å€¼ 5")
            return 5

        elif question_type == "text":
            # æ–‡å­—é¡Œï¼šç›´æ¥è¿”å›
            return llm_response

        return llm_response

    def _get_error_fallback_answer(self, question_type: str) -> Any:
        """
        ç•¶ LLM å®Œå…¨å¤±æ•—æ™‚çš„ç·Šæ€¥ fallback
        åƒ…åœ¨ç•°å¸¸æƒ…æ³ä¸‹ä½¿ç”¨ï¼Œé¿å…æ•´å€‹å•å·å¤±æ•—

        Args:
            question_type: å•é¡Œé¡å‹

        Returns:
            æœ€å°å¯ç”¨å›ç­”
        """
        fallbacks = {
            'single_choice': 'ç„¡æ³•å›ç­”',
            'multiple_choice': [],
            'rating': 5,
            'text': 'æŠ±æ­‰ï¼Œç›®å‰ç„¡æ³•æä¾›å›ç­”ã€‚'
        }
        return fallbacks.get(question_type, 'ç„¡æ³•å›ç­”')
